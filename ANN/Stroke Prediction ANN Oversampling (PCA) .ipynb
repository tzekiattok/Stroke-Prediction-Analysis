{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecfcd94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder,LabelEncoder\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, ConfusionMatrixDisplay, precision_score, recall_score, f1_score, classification_report, roc_curve, plot_roc_curve, auc, precision_recall_curve, plot_precision_recall_curve, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "428aa904",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('healthcare-dataset-stroke-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64ad71e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5110 entries, 0 to 5109\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 5110 non-null   int64  \n",
      " 1   gender             5110 non-null   object \n",
      " 2   age                5110 non-null   float64\n",
      " 3   hypertension       5110 non-null   int64  \n",
      " 4   heart_disease      5110 non-null   int64  \n",
      " 5   ever_married       5110 non-null   object \n",
      " 6   work_type          5110 non-null   object \n",
      " 7   Residence_type     5110 non-null   object \n",
      " 8   avg_glucose_level  5110 non-null   float64\n",
      " 9   bmi                4909 non-null   float64\n",
      " 10  smoking_status     5110 non-null   object \n",
      " 11  stroke             5110 non-null   int64  \n",
      "dtypes: float64(3), int64(4), object(5)\n",
      "memory usage: 479.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>202.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender   age  hypertension  heart_disease ever_married      work_type  \\\n",
       "0    Male  67.0             0              1          Yes        Private   \n",
       "1  Female  61.0             0              0          Yes  Self-employed   \n",
       "2    Male  80.0             0              1          Yes        Private   \n",
       "3  Female  49.0             0              0          Yes        Private   \n",
       "4  Female  79.0             1              0          Yes  Self-employed   \n",
       "\n",
       "  Residence_type  avg_glucose_level   bmi   smoking_status  stroke  \n",
       "0          Urban             228.69  36.6  formerly smoked       1  \n",
       "1          Rural             202.21   NaN     never smoked       1  \n",
       "2          Rural             105.92  32.5     never smoked       1  \n",
       "3          Urban             171.23  34.4           smokes       1  \n",
       "4          Rural             174.12  24.0     never smoked       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove the ID column\n",
    "df.info()\n",
    "df.drop('id', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b24ea53",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_bmi_pipe = Pipeline( steps=[ \n",
    "                               ('scale',StandardScaler()),\n",
    "                               ('lr',DecisionTreeRegressor(random_state=0))\n",
    "                              ])\n",
    "X = df[['age','gender','bmi']].copy()\n",
    "X.gender = X.gender.replace({'Male':0,'Female':1,'Other':-1}).astype(np.uint8)\n",
    "\n",
    "Missing = X[X.bmi.isna()]\n",
    "X = X[~X.bmi.isna()]\n",
    "Y = X.pop('bmi')\n",
    "DT_bmi_pipe.fit(X,Y)\n",
    "predicted_bmi = pd.Series(DT_bmi_pipe.predict(Missing[['age','gender']]),index=Missing.index)\n",
    "df.loc[Missing.index,'bmi'] = predicted_bmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "196efb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Label Encode Binary\n",
    "residence_type = df['Residence_type'].unique()\n",
    "ever_married = df['ever_married'].unique()\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(residence_type)\n",
    "df['Residence_type'] = le.transform(df['Residence_type'])\n",
    "\n",
    "le.fit(ever_married)\n",
    "df['ever_married'] = le.transform(df['ever_married'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de5d7d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Private</td>\n",
       "      <td>1</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>0</td>\n",
       "      <td>202.21</td>\n",
       "      <td>29.879487</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Private</td>\n",
       "      <td>0</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Private</td>\n",
       "      <td>1</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.400000</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>0</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5105</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Private</td>\n",
       "      <td>1</td>\n",
       "      <td>83.75</td>\n",
       "      <td>28.476923</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5106</th>\n",
       "      <td>Female</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>1</td>\n",
       "      <td>125.20</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5107</th>\n",
       "      <td>Female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>0</td>\n",
       "      <td>82.99</td>\n",
       "      <td>30.600000</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108</th>\n",
       "      <td>Male</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Private</td>\n",
       "      <td>0</td>\n",
       "      <td>166.29</td>\n",
       "      <td>25.600000</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>Female</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Govt_job</td>\n",
       "      <td>1</td>\n",
       "      <td>85.28</td>\n",
       "      <td>26.200000</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5110 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender   age  hypertension  heart_disease  ever_married      work_type  \\\n",
       "0       Male  67.0             0              1             1        Private   \n",
       "1     Female  61.0             0              0             1  Self-employed   \n",
       "2       Male  80.0             0              1             1        Private   \n",
       "3     Female  49.0             0              0             1        Private   \n",
       "4     Female  79.0             1              0             1  Self-employed   \n",
       "...      ...   ...           ...            ...           ...            ...   \n",
       "5105  Female  80.0             1              0             1        Private   \n",
       "5106  Female  81.0             0              0             1  Self-employed   \n",
       "5107  Female  35.0             0              0             1  Self-employed   \n",
       "5108    Male  51.0             0              0             1        Private   \n",
       "5109  Female  44.0             0              0             1       Govt_job   \n",
       "\n",
       "      Residence_type  avg_glucose_level        bmi   smoking_status  stroke  \n",
       "0                  1             228.69  36.600000  formerly smoked       1  \n",
       "1                  0             202.21  29.879487     never smoked       1  \n",
       "2                  0             105.92  32.500000     never smoked       1  \n",
       "3                  1             171.23  34.400000           smokes       1  \n",
       "4                  0             174.12  24.000000     never smoked       1  \n",
       "...              ...                ...        ...              ...     ...  \n",
       "5105               1              83.75  28.476923     never smoked       0  \n",
       "5106               1             125.20  40.000000     never smoked       0  \n",
       "5107               0              82.99  30.600000     never smoked       0  \n",
       "5108               0             166.29  25.600000  formerly smoked       0  \n",
       "5109               1              85.28  26.200000          Unknown       0  \n",
       "\n",
       "[5110 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n",
    "#Label Encode -> One Hot Encode -> PCA -> Splitting -> Outlier Detection -> SMOTE X_train and y_train -> Bayes Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd162ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['gender', 'age', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', \n",
    "       'avg_glucose_level', 'bmi', 'smoking_status']]\n",
    "y = df['stroke']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89f4477e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One Hot Encode everything\n",
    "encoder = ColumnTransformer(transformers=[('onehot', OneHotEncoder(), ['gender', 'work_type', 'smoking_status'])], remainder='passthrough')\n",
    "X = np.array(encoder.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0c7f1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12730d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e677312b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Isolation Forest\n",
    "iso = IsolationForest(contamination=0.1)\n",
    "yhat = iso.fit_predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e472680a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask, :], y_train[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "164ec75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROS\n",
    "X_ros, y_ros = RandomOverSampler().fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1294134e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cumulative Variance Ratio</th>\n",
       "      <th>Explained Variance Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.147557</td>\n",
       "      <td>0.147557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.278531</td>\n",
       "      <td>0.130974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.377939</td>\n",
       "      <td>0.099408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.468356</td>\n",
       "      <td>0.090417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.540715</td>\n",
       "      <td>0.072359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.608190</td>\n",
       "      <td>0.067475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.667686</td>\n",
       "      <td>0.059496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.724026</td>\n",
       "      <td>0.056340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.775918</td>\n",
       "      <td>0.051892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.824861</td>\n",
       "      <td>0.048943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.869990</td>\n",
       "      <td>0.045129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.904593</td>\n",
       "      <td>0.034602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.936766</td>\n",
       "      <td>0.032173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.966319</td>\n",
       "      <td>0.029553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.986727</td>\n",
       "      <td>0.020408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Cumulative Variance Ratio  Explained Variance Ratio\n",
       "0                    0.147557                  0.147557\n",
       "1                    0.278531                  0.130974\n",
       "2                    0.377939                  0.099408\n",
       "3                    0.468356                  0.090417\n",
       "4                    0.540715                  0.072359\n",
       "5                    0.608190                  0.067475\n",
       "6                    0.667686                  0.059496\n",
       "7                    0.724026                  0.056340\n",
       "8                    0.775918                  0.051892\n",
       "9                    0.824861                  0.048943\n",
       "10                   0.869990                  0.045129\n",
       "11                   0.904593                  0.034602\n",
       "12                   0.936766                  0.032173\n",
       "13                   0.966319                  0.029553\n",
       "14                   0.986727                  0.020408"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca_test = PCA(n_components=15)\n",
    "pca_test.fit(X_ros)\n",
    "sns.set(style='whitegrid')\n",
    "plt.plot(np.cumsum(pca_test.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "plt.axvline(linewidth=4, color='r', linestyle = '--', x=14, ymin=0, ymax=1)\n",
    "display(plt.show())\n",
    "evr = pca_test.explained_variance_ratio_\n",
    "cvr = np.cumsum(pca_test.explained_variance_ratio_)\n",
    "pca_df = pd.DataFrame()\n",
    "pca_df['Cumulative Variance Ratio'] = cvr\n",
    "pca_df['Explained Variance Ratio'] = evr\n",
    "display(pca_df.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ccf65cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=12)\n",
    "X_ros = pca.fit_transform(X_ros)\n",
    "X_test = pca.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08dda3a",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f25c74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential  \n",
    "from keras.layers import Dense, Activation\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b89bab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_classifier(optimizer = 'adam'):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(layers.Dense(8, kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01), activation=tf.nn.relu))\n",
    "    model.add(layers.Dense(8, kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01), activation=tf.nn.relu))\n",
    "    tf.keras.layers.Dropout(0.6)\n",
    "    model.add(layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "    model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f6e6579",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = KerasClassifier(build_fn = ann_classifier, batch_size = 32, epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8956ebab",
   "metadata": {},
   "source": [
    "# Before tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc598bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_model = tf.keras.models.Sequential()\n",
    "prior_model.add(layers.Dense(8, kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01), activation=tf.nn.relu))\n",
    "prior_model.add(layers.Dense(8, kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01), activation=tf.nn.relu))\n",
    "tf.keras.layers.Dropout(0.4)\n",
    "prior_model.add(layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "prior_model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eda4508d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "221/221 [==============================] - 1s 518us/step - loss: 0.8300 - accuracy: 0.5713\n",
      "Epoch 2/100\n",
      "221/221 [==============================] - 0s 518us/step - loss: 0.6558 - accuracy: 0.7385\n",
      "Epoch 3/100\n",
      "221/221 [==============================] - 0s 537us/step - loss: 0.5816 - accuracy: 0.7646\n",
      "Epoch 4/100\n",
      "221/221 [==============================] - 0s 534us/step - loss: 0.5536 - accuracy: 0.7608\n",
      "Epoch 5/100\n",
      "221/221 [==============================] - 0s 523us/step - loss: 0.5387 - accuracy: 0.7595\n",
      "Epoch 6/100\n",
      "221/221 [==============================] - 0s 482us/step - loss: 0.5290 - accuracy: 0.7629\n",
      "Epoch 7/100\n",
      "221/221 [==============================] - 0s 504us/step - loss: 0.5218 - accuracy: 0.7649\n",
      "Epoch 8/100\n",
      "221/221 [==============================] - 0s 530us/step - loss: 0.5147 - accuracy: 0.7707\n",
      "Epoch 9/100\n",
      "221/221 [==============================] - 0s 482us/step - loss: 0.5100 - accuracy: 0.7721\n",
      "Epoch 10/100\n",
      "221/221 [==============================] - 0s 459us/step - loss: 0.5050 - accuracy: 0.7745\n",
      "Epoch 11/100\n",
      "221/221 [==============================] - 0s 464us/step - loss: 0.5012 - accuracy: 0.7744\n",
      "Epoch 12/100\n",
      "221/221 [==============================] - 0s 481us/step - loss: 0.4982 - accuracy: 0.7795\n",
      "Epoch 13/100\n",
      "221/221 [==============================] - 0s 464us/step - loss: 0.4951 - accuracy: 0.7812\n",
      "Epoch 14/100\n",
      "221/221 [==============================] - 0s 518us/step - loss: 0.4919 - accuracy: 0.7840\n",
      "Epoch 15/100\n",
      "221/221 [==============================] - 0s 468us/step - loss: 0.4897 - accuracy: 0.7830\n",
      "Epoch 16/100\n",
      "221/221 [==============================] - 0s 473us/step - loss: 0.4871 - accuracy: 0.7847\n",
      "Epoch 17/100\n",
      "221/221 [==============================] - 0s 491us/step - loss: 0.4852 - accuracy: 0.7849\n",
      "Epoch 18/100\n",
      "221/221 [==============================] - 0s 473us/step - loss: 0.4828 - accuracy: 0.7856\n",
      "Epoch 19/100\n",
      "221/221 [==============================] - 0s 464us/step - loss: 0.4815 - accuracy: 0.7863\n",
      "Epoch 20/100\n",
      "221/221 [==============================] - 0s 473us/step - loss: 0.4800 - accuracy: 0.7870\n",
      "Epoch 21/100\n",
      "221/221 [==============================] - 0s 459us/step - loss: 0.4774 - accuracy: 0.7917\n",
      "Epoch 22/100\n",
      "221/221 [==============================] - 0s 464us/step - loss: 0.4770 - accuracy: 0.7909\n",
      "Epoch 23/100\n",
      "221/221 [==============================] - 0s 468us/step - loss: 0.4749 - accuracy: 0.7905\n",
      "Epoch 24/100\n",
      "221/221 [==============================] - 0s 473us/step - loss: 0.4740 - accuracy: 0.7909\n",
      "Epoch 25/100\n",
      "221/221 [==============================] - 0s 459us/step - loss: 0.4727 - accuracy: 0.7921\n",
      "Epoch 26/100\n",
      "221/221 [==============================] - 0s 468us/step - loss: 0.4722 - accuracy: 0.7912\n",
      "Epoch 27/100\n",
      "221/221 [==============================] - 0s 464us/step - loss: 0.4712 - accuracy: 0.7938\n",
      "Epoch 28/100\n",
      "221/221 [==============================] - 0s 468us/step - loss: 0.4698 - accuracy: 0.7939\n",
      "Epoch 29/100\n",
      "221/221 [==============================] - 0s 509us/step - loss: 0.4694 - accuracy: 0.7918\n",
      "Epoch 30/100\n",
      "221/221 [==============================] - 0s 473us/step - loss: 0.4685 - accuracy: 0.7972\n",
      "Epoch 31/100\n",
      "221/221 [==============================] - 0s 509us/step - loss: 0.4673 - accuracy: 0.7939\n",
      "Epoch 32/100\n",
      "221/221 [==============================] - 0s 477us/step - loss: 0.4669 - accuracy: 0.7942\n",
      "Epoch 33/100\n",
      "221/221 [==============================] - 0s 482us/step - loss: 0.4658 - accuracy: 0.7965\n",
      "Epoch 34/100\n",
      "221/221 [==============================] - 0s 473us/step - loss: 0.4646 - accuracy: 0.7982\n",
      "Epoch 35/100\n",
      "221/221 [==============================] - 0s 468us/step - loss: 0.4637 - accuracy: 0.7975\n",
      "Epoch 36/100\n",
      "221/221 [==============================] - 0s 473us/step - loss: 0.4626 - accuracy: 0.7945\n",
      "Epoch 37/100\n",
      "221/221 [==============================] - 0s 468us/step - loss: 0.4623 - accuracy: 0.7993\n",
      "Epoch 38/100\n",
      "221/221 [==============================] - 0s 459us/step - loss: 0.4620 - accuracy: 0.7984\n",
      "Epoch 39/100\n",
      "221/221 [==============================] - 0s 464us/step - loss: 0.4606 - accuracy: 0.8033\n",
      "Epoch 40/100\n",
      "221/221 [==============================] - 0s 473us/step - loss: 0.4602 - accuracy: 0.8003\n",
      "Epoch 41/100\n",
      "221/221 [==============================] - 0s 464us/step - loss: 0.4593 - accuracy: 0.8004\n",
      "Epoch 42/100\n",
      "221/221 [==============================] - 0s 468us/step - loss: 0.4575 - accuracy: 0.8034\n",
      "Epoch 43/100\n",
      "221/221 [==============================] - 0s 468us/step - loss: 0.4568 - accuracy: 0.8000\n",
      "Epoch 44/100\n",
      "221/221 [==============================] - 0s 468us/step - loss: 0.4564 - accuracy: 0.8081\n",
      "Epoch 45/100\n",
      "221/221 [==============================] - 0s 468us/step - loss: 0.4552 - accuracy: 0.8071\n",
      "Epoch 46/100\n",
      "221/221 [==============================] - 0s 464us/step - loss: 0.4545 - accuracy: 0.8066\n",
      "Epoch 47/100\n",
      "221/221 [==============================] - 0s 459us/step - loss: 0.4532 - accuracy: 0.8068\n",
      "Epoch 48/100\n",
      "221/221 [==============================] - 0s 464us/step - loss: 0.4517 - accuracy: 0.8106\n",
      "Epoch 49/100\n",
      "221/221 [==============================] - 0s 469us/step - loss: 0.4505 - accuracy: 0.8123\n",
      "Epoch 50/100\n",
      "221/221 [==============================] - 0s 477us/step - loss: 0.4499 - accuracy: 0.8134\n",
      "Epoch 51/100\n",
      "221/221 [==============================] - 0s 468us/step - loss: 0.4479 - accuracy: 0.8163\n",
      "Epoch 52/100\n",
      "221/221 [==============================] - 0s 468us/step - loss: 0.4474 - accuracy: 0.8160\n",
      "Epoch 53/100\n",
      "221/221 [==============================] - 0s 506us/step - loss: 0.4476 - accuracy: 0.8137\n",
      "Epoch 54/100\n",
      "221/221 [==============================] - 0s 468us/step - loss: 0.4467 - accuracy: 0.8156\n",
      "Epoch 55/100\n",
      "221/221 [==============================] - 0s 459us/step - loss: 0.4463 - accuracy: 0.8140\n",
      "Epoch 56/100\n",
      "221/221 [==============================] - 0s 451us/step - loss: 0.4446 - accuracy: 0.8150\n",
      "Epoch 57/100\n",
      "221/221 [==============================] - 0s 455us/step - loss: 0.4440 - accuracy: 0.8175\n",
      "Epoch 58/100\n",
      "221/221 [==============================] - 0s 492us/step - loss: 0.4437 - accuracy: 0.8175\n",
      "Epoch 59/100\n",
      "221/221 [==============================] - 0s 531us/step - loss: 0.4434 - accuracy: 0.8164\n",
      "Epoch 60/100\n",
      "221/221 [==============================] - 0s 485us/step - loss: 0.4427 - accuracy: 0.8184\n",
      "Epoch 61/100\n",
      "221/221 [==============================] - 0s 491us/step - loss: 0.4430 - accuracy: 0.8188\n",
      "Epoch 62/100\n",
      "221/221 [==============================] - 0s 510us/step - loss: 0.4425 - accuracy: 0.8188\n",
      "Epoch 63/100\n",
      "221/221 [==============================] - 0s 509us/step - loss: 0.4415 - accuracy: 0.8192\n",
      "Epoch 64/100\n",
      "221/221 [==============================] - 0s 486us/step - loss: 0.4408 - accuracy: 0.8209\n",
      "Epoch 65/100\n",
      "221/221 [==============================] - 0s 502us/step - loss: 0.4414 - accuracy: 0.8165\n",
      "Epoch 66/100\n",
      "221/221 [==============================] - 0s 509us/step - loss: 0.4402 - accuracy: 0.8201\n",
      "Epoch 67/100\n",
      "221/221 [==============================] - 0s 605us/step - loss: 0.4393 - accuracy: 0.8215\n",
      "Epoch 68/100\n",
      "221/221 [==============================] - 0s 527us/step - loss: 0.4398 - accuracy: 0.8225\n",
      "Epoch 69/100\n",
      "221/221 [==============================] - 0s 491us/step - loss: 0.4384 - accuracy: 0.8226\n",
      "Epoch 70/100\n",
      "221/221 [==============================] - 0s 509us/step - loss: 0.4381 - accuracy: 0.8202\n",
      "Epoch 71/100\n",
      "221/221 [==============================] - 0s 518us/step - loss: 0.4374 - accuracy: 0.8208\n",
      "Epoch 72/100\n",
      "221/221 [==============================] - 0s 500us/step - loss: 0.4376 - accuracy: 0.8245\n",
      "Epoch 73/100\n",
      "221/221 [==============================] - 0s 523us/step - loss: 0.4375 - accuracy: 0.8190\n",
      "Epoch 74/100\n",
      "221/221 [==============================] - 0s 514us/step - loss: 0.4369 - accuracy: 0.8187\n",
      "Epoch 75/100\n",
      "221/221 [==============================] - 0s 501us/step - loss: 0.4369 - accuracy: 0.8218\n",
      "Epoch 76/100\n",
      "221/221 [==============================] - 0s 500us/step - loss: 0.4369 - accuracy: 0.8233\n",
      "Epoch 77/100\n",
      "221/221 [==============================] - 0s 491us/step - loss: 0.4368 - accuracy: 0.8243\n",
      "Epoch 78/100\n",
      "221/221 [==============================] - 0s 527us/step - loss: 0.4353 - accuracy: 0.8218\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221/221 [==============================] - 0s 564us/step - loss: 0.4357 - accuracy: 0.8197\n",
      "Epoch 80/100\n",
      "221/221 [==============================] - 0s 532us/step - loss: 0.4338 - accuracy: 0.8249\n",
      "Epoch 81/100\n",
      "221/221 [==============================] - 0s 546us/step - loss: 0.4345 - accuracy: 0.8219\n",
      "Epoch 82/100\n",
      "221/221 [==============================] - 0s 532us/step - loss: 0.4348 - accuracy: 0.8231\n",
      "Epoch 83/100\n",
      "221/221 [==============================] - 0s 523us/step - loss: 0.4345 - accuracy: 0.8177\n",
      "Epoch 84/100\n",
      "221/221 [==============================] - 0s 509us/step - loss: 0.4339 - accuracy: 0.8219\n",
      "Epoch 85/100\n",
      "221/221 [==============================] - 0s 505us/step - loss: 0.4343 - accuracy: 0.8229\n",
      "Epoch 86/100\n",
      "221/221 [==============================] - 0s 468us/step - loss: 0.4335 - accuracy: 0.8232\n",
      "Epoch 87/100\n",
      "221/221 [==============================] - 0s 479us/step - loss: 0.4333 - accuracy: 0.8233\n",
      "Epoch 88/100\n",
      "221/221 [==============================] - 0s 464us/step - loss: 0.4326 - accuracy: 0.8207\n",
      "Epoch 89/100\n",
      "221/221 [==============================] - 0s 464us/step - loss: 0.4318 - accuracy: 0.8216\n",
      "Epoch 90/100\n",
      "221/221 [==============================] - 0s 500us/step - loss: 0.4322 - accuracy: 0.8194\n",
      "Epoch 91/100\n",
      "221/221 [==============================] - 0s 491us/step - loss: 0.4315 - accuracy: 0.8215\n",
      "Epoch 92/100\n",
      "221/221 [==============================] - 0s 491us/step - loss: 0.4309 - accuracy: 0.8221\n",
      "Epoch 93/100\n",
      "221/221 [==============================] - 0s 491us/step - loss: 0.4319 - accuracy: 0.8204\n",
      "Epoch 94/100\n",
      "221/221 [==============================] - 0s 505us/step - loss: 0.4312 - accuracy: 0.8222\n",
      "Epoch 95/100\n",
      "221/221 [==============================] - 0s 496us/step - loss: 0.4306 - accuracy: 0.8233\n",
      "Epoch 96/100\n",
      "221/221 [==============================] - 0s 491us/step - loss: 0.4312 - accuracy: 0.8202\n",
      "Epoch 97/100\n",
      "221/221 [==============================] - 0s 491us/step - loss: 0.4318 - accuracy: 0.8205\n",
      "Epoch 98/100\n",
      "221/221 [==============================] - 0s 500us/step - loss: 0.4297 - accuracy: 0.8211\n",
      "Epoch 99/100\n",
      "221/221 [==============================] - 0s 491us/step - loss: 0.4307 - accuracy: 0.8211\n",
      "Epoch 100/100\n",
      "221/221 [==============================] - 0s 482us/step - loss: 0.4305 - accuracy: 0.8252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26020e72f40>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 100\n",
    "prior_model.fit(X_ros, y_ros, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13f62f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 419us/step - loss: 0.9947 - accuracy: 0.5020\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = prior_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe5c87e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.501957\n",
      "Precision: 0.085610\n",
      "Recall: 0.870370\n",
      "F1 score: 0.155887\n",
      "ROC score: 0.675888\n",
      "----------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.48      0.65       968\n",
      "           1       0.09      0.87      0.16        54\n",
      "\n",
      "    accuracy                           0.50      1022\n",
      "   macro avg       0.54      0.68      0.40      1022\n",
      "weighted avg       0.94      0.50      0.62      1022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred=(prior_model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print('F1 score: %f' % f1)\n",
    "roc = roc_auc_score(y_test, y_pred)\n",
    "print('ROC score: %f' % roc)\n",
    "print('----------------------------')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813deb5e",
   "metadata": {},
   "source": [
    "# Tune ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1165f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "283/283 [==============================] - 1s 472us/step - loss: 0.6979 - accuracy: 0.6915\n",
      "Epoch 2/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.5876 - accuracy: 0.7457\n",
      "Epoch 3/150\n",
      "283/283 [==============================] - 0s 479us/step - loss: 0.5494 - accuracy: 0.7586\n",
      "Epoch 4/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.5335 - accuracy: 0.7608\n",
      "Epoch 5/150\n",
      "283/283 [==============================] - 0s 466us/step - loss: 0.5229 - accuracy: 0.7670\n",
      "Epoch 6/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.5151 - accuracy: 0.7678\n",
      "Epoch 7/150\n",
      "283/283 [==============================] - 0s 463us/step - loss: 0.5092 - accuracy: 0.7694\n",
      "Epoch 8/150\n",
      "283/283 [==============================] - 0s 458us/step - loss: 0.5032 - accuracy: 0.7726\n",
      "Epoch 9/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4984 - accuracy: 0.7757\n",
      "Epoch 10/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4940 - accuracy: 0.7799\n",
      "Epoch 11/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4906 - accuracy: 0.7810\n",
      "Epoch 12/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4868 - accuracy: 0.7871\n",
      "Epoch 13/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4839 - accuracy: 0.7887\n",
      "Epoch 14/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4806 - accuracy: 0.7895\n",
      "Epoch 15/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4789 - accuracy: 0.7904\n",
      "Epoch 16/150\n",
      "283/283 [==============================] - 0s 458us/step - loss: 0.4760 - accuracy: 0.7925\n",
      "Epoch 17/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4731 - accuracy: 0.8000\n",
      "Epoch 18/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4715 - accuracy: 0.8018\n",
      "Epoch 19/150\n",
      "283/283 [==============================] - 0s 458us/step - loss: 0.4700 - accuracy: 0.8014\n",
      "Epoch 20/150\n",
      "283/283 [==============================] - 0s 472us/step - loss: 0.4678 - accuracy: 0.7994\n",
      "Epoch 21/150\n",
      "283/283 [==============================] - 0s 482us/step - loss: 0.4662 - accuracy: 0.8031\n",
      "Epoch 22/150\n",
      "283/283 [==============================] - 0s 489us/step - loss: 0.4643 - accuracy: 0.8010\n",
      "Epoch 23/150\n",
      "283/283 [==============================] - 0s 475us/step - loss: 0.4628 - accuracy: 0.8061\n",
      "Epoch 24/150\n",
      "283/283 [==============================] - 0s 504us/step - loss: 0.4607 - accuracy: 0.8004\n",
      "Epoch 25/150\n",
      "283/283 [==============================] - 0s 482us/step - loss: 0.4591 - accuracy: 0.8075\n",
      "Epoch 26/150\n",
      "283/283 [==============================] - 0s 472us/step - loss: 0.4572 - accuracy: 0.8025\n",
      "Epoch 27/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4561 - accuracy: 0.8055\n",
      "Epoch 28/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4541 - accuracy: 0.8076\n",
      "Epoch 29/150\n",
      "283/283 [==============================] - 0s 475us/step - loss: 0.4527 - accuracy: 0.8061\n",
      "Epoch 30/150\n",
      "283/283 [==============================] - 0s 493us/step - loss: 0.4518 - accuracy: 0.8106\n",
      "Epoch 31/150\n",
      "283/283 [==============================] - 0s 472us/step - loss: 0.4499 - accuracy: 0.8112\n",
      "Epoch 32/150\n",
      "283/283 [==============================] - 0s 472us/step - loss: 0.4488 - accuracy: 0.8083\n",
      "Epoch 33/150\n",
      "283/283 [==============================] - 0s 482us/step - loss: 0.4468 - accuracy: 0.8099\n",
      "Epoch 34/150\n",
      "283/283 [==============================] - 0s 472us/step - loss: 0.4472 - accuracy: 0.8134\n",
      "Epoch 35/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4456 - accuracy: 0.8127\n",
      "Epoch 36/150\n",
      "283/283 [==============================] - 0s 454us/step - loss: 0.4447 - accuracy: 0.8098\n",
      "Epoch 37/150\n",
      "283/283 [==============================] - 0s 458us/step - loss: 0.4434 - accuracy: 0.8115\n",
      "Epoch 38/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4417 - accuracy: 0.8132\n",
      "Epoch 39/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4411 - accuracy: 0.8139\n",
      "Epoch 40/150\n",
      "283/283 [==============================] - 0s 472us/step - loss: 0.4401 - accuracy: 0.8137\n",
      "Epoch 41/150\n",
      "283/283 [==============================] - 0s 472us/step - loss: 0.4388 - accuracy: 0.8163\n",
      "Epoch 42/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4380 - accuracy: 0.8161\n",
      "Epoch 43/150\n",
      "283/283 [==============================] - 0s 472us/step - loss: 0.4360 - accuracy: 0.8204\n",
      "Epoch 44/150\n",
      "283/283 [==============================] - 0s 458us/step - loss: 0.4363 - accuracy: 0.8195\n",
      "Epoch 45/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4352 - accuracy: 0.8215\n",
      "Epoch 46/150\n",
      "283/283 [==============================] - 0s 472us/step - loss: 0.4341 - accuracy: 0.8208\n",
      "Epoch 47/150\n",
      "283/283 [==============================] - 0s 472us/step - loss: 0.4321 - accuracy: 0.8216\n",
      "Epoch 48/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4327 - accuracy: 0.8215\n",
      "Epoch 49/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4332 - accuracy: 0.8226\n",
      "Epoch 50/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4304 - accuracy: 0.8240\n",
      "Epoch 51/150\n",
      "283/283 [==============================] - 0s 475us/step - loss: 0.4307 - accuracy: 0.8231\n",
      "Epoch 52/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4296 - accuracy: 0.8280\n",
      "Epoch 53/150\n",
      "283/283 [==============================] - 0s 472us/step - loss: 0.4294 - accuracy: 0.8267\n",
      "Epoch 54/150\n",
      "283/283 [==============================] - 0s 472us/step - loss: 0.4284 - accuracy: 0.8202\n",
      "Epoch 55/150\n",
      "283/283 [==============================] - 0s 475us/step - loss: 0.4277 - accuracy: 0.8300\n",
      "Epoch 56/150\n",
      "283/283 [==============================] - 0s 458us/step - loss: 0.4266 - accuracy: 0.8274\n",
      "Epoch 57/150\n",
      "283/283 [==============================] - 0s 476us/step - loss: 0.4262 - accuracy: 0.8286\n",
      "Epoch 58/150\n",
      "283/283 [==============================] - 0s 475us/step - loss: 0.4262 - accuracy: 0.8284\n",
      "Epoch 59/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4252 - accuracy: 0.8297\n",
      "Epoch 60/150\n",
      "283/283 [==============================] - 0s 475us/step - loss: 0.4241 - accuracy: 0.8291\n",
      "Epoch 61/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4251 - accuracy: 0.8284\n",
      "Epoch 62/150\n",
      "283/283 [==============================] - 0s 479us/step - loss: 0.4243 - accuracy: 0.8289\n",
      "Epoch 63/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4231 - accuracy: 0.8263\n",
      "Epoch 64/150\n",
      "283/283 [==============================] - 0s 475us/step - loss: 0.4222 - accuracy: 0.8315\n",
      "Epoch 65/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4220 - accuracy: 0.8321\n",
      "Epoch 66/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4212 - accuracy: 0.8287\n",
      "Epoch 67/150\n",
      "283/283 [==============================] - 0s 482us/step - loss: 0.4213 - accuracy: 0.8313\n",
      "Epoch 68/150\n",
      "283/283 [==============================] - 0s 485us/step - loss: 0.4197 - accuracy: 0.8281\n",
      "Epoch 69/150\n",
      "283/283 [==============================] - 0s 482us/step - loss: 0.4202 - accuracy: 0.8296\n",
      "Epoch 70/150\n",
      "283/283 [==============================] - 0s 462us/step - loss: 0.4191 - accuracy: 0.8328\n",
      "Epoch 71/150\n",
      "283/283 [==============================] - 0s 485us/step - loss: 0.4178 - accuracy: 0.8289\n",
      "Epoch 72/150\n",
      "283/283 [==============================] - 0s 479us/step - loss: 0.4190 - accuracy: 0.8318\n",
      "Epoch 73/150\n",
      "283/283 [==============================] - 0s 482us/step - loss: 0.4182 - accuracy: 0.8298\n",
      "Epoch 74/150\n",
      "283/283 [==============================] - 0s 489us/step - loss: 0.4183 - accuracy: 0.8321\n",
      "Epoch 75/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4180 - accuracy: 0.8335\n",
      "Epoch 76/150\n",
      "283/283 [==============================] - 0s 475us/step - loss: 0.4166 - accuracy: 0.8322\n",
      "Epoch 77/150\n",
      "283/283 [==============================] - 0s 497us/step - loss: 0.4174 - accuracy: 0.8277\n",
      "Epoch 78/150\n",
      "283/283 [==============================] - 0s 514us/step - loss: 0.4158 - accuracy: 0.8313\n",
      "Epoch 79/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283/283 [==============================] - 0s 465us/step - loss: 0.4164 - accuracy: 0.8317\n",
      "Epoch 80/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4158 - accuracy: 0.8352\n",
      "Epoch 81/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4164 - accuracy: 0.8297\n",
      "Epoch 82/150\n",
      "283/283 [==============================] - 0s 472us/step - loss: 0.4142 - accuracy: 0.8328\n",
      "Epoch 83/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4133 - accuracy: 0.8332\n",
      "Epoch 84/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4130 - accuracy: 0.8352\n",
      "Epoch 85/150\n",
      "283/283 [==============================] - 0s 472us/step - loss: 0.4129 - accuracy: 0.8345\n",
      "Epoch 86/150\n",
      "283/283 [==============================] - 0s 482us/step - loss: 0.4127 - accuracy: 0.8330\n",
      "Epoch 87/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4120 - accuracy: 0.8315\n",
      "Epoch 88/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4112 - accuracy: 0.8355\n",
      "Epoch 89/150\n",
      "283/283 [==============================] - 0s 464us/step - loss: 0.4105 - accuracy: 0.8366\n",
      "Epoch 90/150\n",
      "283/283 [==============================] - 0s 464us/step - loss: 0.4114 - accuracy: 0.8366\n",
      "Epoch 91/150\n",
      "283/283 [==============================] - 0s 471us/step - loss: 0.4093 - accuracy: 0.8365\n",
      "Epoch 92/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4087 - accuracy: 0.8365\n",
      "Epoch 93/150\n",
      "283/283 [==============================] - 0s 472us/step - loss: 0.4082 - accuracy: 0.8369\n",
      "Epoch 94/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4080 - accuracy: 0.8388\n",
      "Epoch 95/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4055 - accuracy: 0.8383\n",
      "Epoch 96/150\n",
      "283/283 [==============================] - 0s 478us/step - loss: 0.4053 - accuracy: 0.8348\n",
      "Epoch 97/150\n",
      "283/283 [==============================] - 0s 475us/step - loss: 0.4044 - accuracy: 0.8421\n",
      "Epoch 98/150\n",
      "283/283 [==============================] - 0s 464us/step - loss: 0.4024 - accuracy: 0.8419\n",
      "Epoch 99/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4034 - accuracy: 0.8427\n",
      "Epoch 100/150\n",
      "283/283 [==============================] - 0s 458us/step - loss: 0.4034 - accuracy: 0.8414\n",
      "Epoch 101/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4021 - accuracy: 0.8417\n",
      "Epoch 102/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4024 - accuracy: 0.8399\n",
      "Epoch 103/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4011 - accuracy: 0.8429\n",
      "Epoch 104/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4002 - accuracy: 0.8438\n",
      "Epoch 105/150\n",
      "283/283 [==============================] - 0s 472us/step - loss: 0.4000 - accuracy: 0.8448\n",
      "Epoch 106/150\n",
      "283/283 [==============================] - 0s 482us/step - loss: 0.3998 - accuracy: 0.8446\n",
      "Epoch 107/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4003 - accuracy: 0.8444\n",
      "Epoch 108/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.3986 - accuracy: 0.8489\n",
      "Epoch 109/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.3995 - accuracy: 0.8458\n",
      "Epoch 110/150\n",
      "283/283 [==============================] - 0s 462us/step - loss: 0.3990 - accuracy: 0.8437\n",
      "Epoch 111/150\n",
      "283/283 [==============================] - 0s 521us/step - loss: 0.3987 - accuracy: 0.8464\n",
      "Epoch 112/150\n",
      "283/283 [==============================] - 0s 454us/step - loss: 0.3986 - accuracy: 0.8460\n",
      "Epoch 113/150\n",
      "283/283 [==============================] - 0s 457us/step - loss: 0.3976 - accuracy: 0.8453\n",
      "Epoch 114/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.3986 - accuracy: 0.8448\n",
      "Epoch 115/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.3953 - accuracy: 0.8481\n",
      "Epoch 116/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.3963 - accuracy: 0.8504\n",
      "Epoch 117/150\n",
      "283/283 [==============================] - 0s 458us/step - loss: 0.3950 - accuracy: 0.8451\n",
      "Epoch 118/150\n",
      "283/283 [==============================] - 0s 458us/step - loss: 0.3944 - accuracy: 0.8461\n",
      "Epoch 119/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.3959 - accuracy: 0.8487\n",
      "Epoch 120/150\n",
      "283/283 [==============================] - 0s 458us/step - loss: 0.3949 - accuracy: 0.8438\n",
      "Epoch 121/150\n",
      "283/283 [==============================] - 0s 457us/step - loss: 0.3942 - accuracy: 0.8487\n",
      "Epoch 122/150\n",
      "283/283 [==============================] - 0s 475us/step - loss: 0.3938 - accuracy: 0.8474\n",
      "Epoch 123/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.3933 - accuracy: 0.8504\n",
      "Epoch 124/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.3926 - accuracy: 0.8485\n",
      "Epoch 125/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.3920 - accuracy: 0.8472\n",
      "Epoch 126/150\n",
      "283/283 [==============================] - 0s 472us/step - loss: 0.3905 - accuracy: 0.8491\n",
      "Epoch 127/150\n",
      "283/283 [==============================] - 0s 486us/step - loss: 0.3909 - accuracy: 0.8519\n",
      "Epoch 128/150\n",
      "283/283 [==============================] - 0s 472us/step - loss: 0.3904 - accuracy: 0.8496\n",
      "Epoch 129/150\n",
      "283/283 [==============================] - 0s 475us/step - loss: 0.3907 - accuracy: 0.8519\n",
      "Epoch 130/150\n",
      "283/283 [==============================] - 0s 475us/step - loss: 0.3897 - accuracy: 0.8515\n",
      "Epoch 131/150\n",
      "283/283 [==============================] - 0s 472us/step - loss: 0.3890 - accuracy: 0.8511\n",
      "Epoch 132/150\n",
      "283/283 [==============================] - 0s 472us/step - loss: 0.3897 - accuracy: 0.8530\n",
      "Epoch 133/150\n",
      "283/283 [==============================] - 0s 500us/step - loss: 0.3892 - accuracy: 0.8501\n",
      "Epoch 134/150\n",
      "283/283 [==============================] - 0s 482us/step - loss: 0.3885 - accuracy: 0.8491\n",
      "Epoch 135/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.3894 - accuracy: 0.8512\n",
      "Epoch 136/150\n",
      "283/283 [==============================] - 0s 518us/step - loss: 0.3889 - accuracy: 0.8522\n",
      "Epoch 137/150\n",
      "283/283 [==============================] - 0s 489us/step - loss: 0.3882 - accuracy: 0.8513\n",
      "Epoch 138/150\n",
      "283/283 [==============================] - 0s 492us/step - loss: 0.3869 - accuracy: 0.8498\n",
      "Epoch 139/150\n",
      "283/283 [==============================] - 0s 500us/step - loss: 0.3874 - accuracy: 0.8481\n",
      "Epoch 140/150\n",
      "283/283 [==============================] - 0s 486us/step - loss: 0.3883 - accuracy: 0.8498\n",
      "Epoch 141/150\n",
      "283/283 [==============================] - 0s 489us/step - loss: 0.3870 - accuracy: 0.8515\n",
      "Epoch 142/150\n",
      "283/283 [==============================] - 0s 486us/step - loss: 0.3872 - accuracy: 0.8501\n",
      "Epoch 143/150\n",
      "283/283 [==============================] - 0s 479us/step - loss: 0.3864 - accuracy: 0.8501\n",
      "Epoch 144/150\n",
      "283/283 [==============================] - 0s 482us/step - loss: 0.3871 - accuracy: 0.8518\n",
      "Epoch 145/150\n",
      "283/283 [==============================] - 0s 482us/step - loss: 0.3867 - accuracy: 0.8498\n",
      "Epoch 146/150\n",
      "283/283 [==============================] - 0s 489us/step - loss: 0.3854 - accuracy: 0.8553\n",
      "Epoch 147/150\n",
      "283/283 [==============================] - 0s 479us/step - loss: 0.3859 - accuracy: 0.8515\n",
      "Epoch 148/150\n",
      "283/283 [==============================] - 0s 500us/step - loss: 0.3866 - accuracy: 0.8513\n",
      "Epoch 149/150\n",
      "283/283 [==============================] - 0s 500us/step - loss: 0.3853 - accuracy: 0.8535\n",
      "Epoch 150/150\n",
      "283/283 [==============================] - 0s 496us/step - loss: 0.3854 - accuracy: 0.8537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x0000026011736C40>,\n",
       "             n_jobs=-1,\n",
       "             param_grid={'batch_size': [25, 32], 'epochs': [50, 100, 150],\n",
       "                         'optimizer': ['adam', 'rmsprop']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'batch_size': [25, 32],\n",
    "             'epochs': [50, 100, 150],\n",
    "             'optimizer': ['adam', 'rmsprop']}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = ann, param_grid = parameters, scoring = 'accuracy', cv = 10, n_jobs = -1)\n",
    "\n",
    "grid_search.fit(X_ros, y_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06a18574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 81.90 %\n",
      "Best Parameters: {'batch_size': 25, 'epochs': 150, 'optimizer': 'rmsprop'}\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\n",
    "print(\"Best Parameters:\", best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024c5b25",
   "metadata": {},
   "source": [
    "# Running ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b0064ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(layers.Dense(8, kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01), activation=tf.nn.relu))\n",
    "model.add(layers.Dense(8, kernel_regularizer=regularizers.l2(0.01), bias_regularizer=regularizers.l2(0.01), activation=tf.nn.relu))\n",
    "tf.keras.layers.Dropout(0.4)\n",
    "model.add(layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f24d57d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "283/283 [==============================] - 1s 482us/step - loss: 0.7685 - accuracy: 0.6379\n",
      "Epoch 2/150\n",
      "283/283 [==============================] - 0s 464us/step - loss: 0.6328 - accuracy: 0.7163\n",
      "Epoch 3/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.5812 - accuracy: 0.7317\n",
      "Epoch 4/150\n",
      "283/283 [==============================] - 0s 497us/step - loss: 0.5565 - accuracy: 0.7492\n",
      "Epoch 5/150\n",
      "283/283 [==============================] - 0s 482us/step - loss: 0.5418 - accuracy: 0.7576\n",
      "Epoch 6/150\n",
      "283/283 [==============================] - 0s 486us/step - loss: 0.5324 - accuracy: 0.7601\n",
      "Epoch 7/150\n",
      "283/283 [==============================] - 0s 479us/step - loss: 0.5253 - accuracy: 0.7601\n",
      "Epoch 8/150\n",
      "283/283 [==============================] - 0s 475us/step - loss: 0.5179 - accuracy: 0.7687\n",
      "Epoch 9/150\n",
      "283/283 [==============================] - 0s 489us/step - loss: 0.5128 - accuracy: 0.7711\n",
      "Epoch 10/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.5070 - accuracy: 0.7731\n",
      "Epoch 11/150\n",
      "283/283 [==============================] - 0s 475us/step - loss: 0.5023 - accuracy: 0.7747\n",
      "Epoch 12/150\n",
      "283/283 [==============================] - 0s 489us/step - loss: 0.4987 - accuracy: 0.7793\n",
      "Epoch 13/150\n",
      "283/283 [==============================] - 0s 479us/step - loss: 0.4954 - accuracy: 0.7781\n",
      "Epoch 14/150\n",
      "283/283 [==============================] - 0s 475us/step - loss: 0.4930 - accuracy: 0.7792\n",
      "Epoch 15/150\n",
      "283/283 [==============================] - 0s 479us/step - loss: 0.4906 - accuracy: 0.7850\n",
      "Epoch 16/150\n",
      "283/283 [==============================] - 0s 475us/step - loss: 0.4882 - accuracy: 0.7840\n",
      "Epoch 17/150\n",
      "283/283 [==============================] - 0s 493us/step - loss: 0.4865 - accuracy: 0.7849\n",
      "Epoch 18/150\n",
      "283/283 [==============================] - 0s 497us/step - loss: 0.4849 - accuracy: 0.7900\n",
      "Epoch 19/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4833 - accuracy: 0.7887\n",
      "Epoch 20/150\n",
      "283/283 [==============================] - 0s 464us/step - loss: 0.4817 - accuracy: 0.7867\n",
      "Epoch 21/150\n",
      "283/283 [==============================] - 0s 475us/step - loss: 0.4806 - accuracy: 0.7833\n",
      "Epoch 22/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4786 - accuracy: 0.7874\n",
      "Epoch 23/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4782 - accuracy: 0.7874\n",
      "Epoch 24/150\n",
      "283/283 [==============================] - 0s 458us/step - loss: 0.4763 - accuracy: 0.7917\n",
      "Epoch 25/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4753 - accuracy: 0.7871\n",
      "Epoch 26/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4741 - accuracy: 0.7873\n",
      "Epoch 27/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4731 - accuracy: 0.7861\n",
      "Epoch 28/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4722 - accuracy: 0.7863\n",
      "Epoch 29/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4710 - accuracy: 0.7844\n",
      "Epoch 30/150\n",
      "283/283 [==============================] - 0s 464us/step - loss: 0.4680 - accuracy: 0.7911\n",
      "Epoch 31/150\n",
      "283/283 [==============================] - 0s 475us/step - loss: 0.4676 - accuracy: 0.7887\n",
      "Epoch 32/150\n",
      "283/283 [==============================] - 0s 475us/step - loss: 0.4660 - accuracy: 0.7914\n",
      "Epoch 33/150\n",
      "283/283 [==============================] - 0s 472us/step - loss: 0.4644 - accuracy: 0.7911\n",
      "Epoch 34/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4647 - accuracy: 0.7921\n",
      "Epoch 35/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4636 - accuracy: 0.7945\n",
      "Epoch 36/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4629 - accuracy: 0.7926\n",
      "Epoch 37/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4615 - accuracy: 0.7935\n",
      "Epoch 38/150\n",
      "283/283 [==============================] - 0s 472us/step - loss: 0.4604 - accuracy: 0.7939\n",
      "Epoch 39/150\n",
      "283/283 [==============================] - 0s 482us/step - loss: 0.4603 - accuracy: 0.7987\n",
      "Epoch 40/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4592 - accuracy: 0.7965\n",
      "Epoch 41/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4574 - accuracy: 0.7956\n",
      "Epoch 42/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4579 - accuracy: 0.7969\n",
      "Epoch 43/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4567 - accuracy: 0.7986\n",
      "Epoch 44/150\n",
      "283/283 [==============================] - 0s 475us/step - loss: 0.4548 - accuracy: 0.7979\n",
      "Epoch 45/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4552 - accuracy: 0.8004\n",
      "Epoch 46/150\n",
      "283/283 [==============================] - 0s 447us/step - loss: 0.4549 - accuracy: 0.7973\n",
      "Epoch 47/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4533 - accuracy: 0.8004\n",
      "Epoch 48/150\n",
      "283/283 [==============================] - 0s 454us/step - loss: 0.4528 - accuracy: 0.8006\n",
      "Epoch 49/150\n",
      "283/283 [==============================] - 0s 458us/step - loss: 0.4519 - accuracy: 0.8007\n",
      "Epoch 50/150\n",
      "283/283 [==============================] - 0s 454us/step - loss: 0.4519 - accuracy: 0.8000\n",
      "Epoch 51/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4507 - accuracy: 0.8016\n",
      "Epoch 52/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4514 - accuracy: 0.8007\n",
      "Epoch 53/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4498 - accuracy: 0.8044\n",
      "Epoch 54/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4500 - accuracy: 0.8034\n",
      "Epoch 55/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4483 - accuracy: 0.8052\n",
      "Epoch 56/150\n",
      "283/283 [==============================] - 0s 458us/step - loss: 0.4482 - accuracy: 0.8061\n",
      "Epoch 57/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4482 - accuracy: 0.8051\n",
      "Epoch 58/150\n",
      "283/283 [==============================] - 0s 475us/step - loss: 0.4465 - accuracy: 0.8054\n",
      "Epoch 59/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4459 - accuracy: 0.8082\n",
      "Epoch 60/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4474 - accuracy: 0.8027\n",
      "Epoch 61/150\n",
      "283/283 [==============================] - 0s 458us/step - loss: 0.4456 - accuracy: 0.8071\n",
      "Epoch 62/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4459 - accuracy: 0.8054\n",
      "Epoch 63/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4448 - accuracy: 0.8040\n",
      "Epoch 64/150\n",
      "283/283 [==============================] - 0s 479us/step - loss: 0.4450 - accuracy: 0.8083\n",
      "Epoch 65/150\n",
      "283/283 [==============================] - 0s 489us/step - loss: 0.4431 - accuracy: 0.8072\n",
      "Epoch 66/150\n",
      "283/283 [==============================] - 0s 493us/step - loss: 0.4430 - accuracy: 0.8095\n",
      "Epoch 67/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4419 - accuracy: 0.8127\n",
      "Epoch 68/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4406 - accuracy: 0.8119\n",
      "Epoch 69/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4412 - accuracy: 0.8100\n",
      "Epoch 70/150\n",
      "283/283 [==============================] - 0s 489us/step - loss: 0.4403 - accuracy: 0.8107\n",
      "Epoch 71/150\n",
      "283/283 [==============================] - 0s 469us/step - loss: 0.4395 - accuracy: 0.8115\n",
      "Epoch 72/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4388 - accuracy: 0.8132\n",
      "Epoch 73/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4384 - accuracy: 0.8140\n",
      "Epoch 74/150\n",
      "283/283 [==============================] - 0s 454us/step - loss: 0.4381 - accuracy: 0.8085\n",
      "Epoch 75/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4372 - accuracy: 0.8143\n",
      "Epoch 76/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4363 - accuracy: 0.8136\n",
      "Epoch 77/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4362 - accuracy: 0.8143\n",
      "Epoch 78/150\n",
      "283/283 [==============================] - 0s 487us/step - loss: 0.4348 - accuracy: 0.8132\n",
      "Epoch 79/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283/283 [==============================] - 0s 465us/step - loss: 0.4352 - accuracy: 0.8129\n",
      "Epoch 80/150\n",
      "283/283 [==============================] - 0s 458us/step - loss: 0.4345 - accuracy: 0.8168\n",
      "Epoch 81/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4337 - accuracy: 0.8211\n",
      "Epoch 82/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4338 - accuracy: 0.8170\n",
      "Epoch 83/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4330 - accuracy: 0.8175\n",
      "Epoch 84/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4317 - accuracy: 0.8188\n",
      "Epoch 85/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4317 - accuracy: 0.8225\n",
      "Epoch 86/150\n",
      "283/283 [==============================] - 0s 493us/step - loss: 0.4314 - accuracy: 0.8177\n",
      "Epoch 87/150\n",
      "283/283 [==============================] - 0s 482us/step - loss: 0.4311 - accuracy: 0.8198\n",
      "Epoch 88/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4310 - accuracy: 0.8195\n",
      "Epoch 89/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4295 - accuracy: 0.8216\n",
      "Epoch 90/150\n",
      "283/283 [==============================] - 0s 486us/step - loss: 0.4295 - accuracy: 0.8194\n",
      "Epoch 91/150\n",
      "283/283 [==============================] - 0s 472us/step - loss: 0.4281 - accuracy: 0.8194\n",
      "Epoch 92/150\n",
      "283/283 [==============================] - 0s 482us/step - loss: 0.4289 - accuracy: 0.8243\n",
      "Epoch 93/150\n",
      "283/283 [==============================] - 0s 472us/step - loss: 0.4281 - accuracy: 0.8222\n",
      "Epoch 94/150\n",
      "283/283 [==============================] - 0s 479us/step - loss: 0.4261 - accuracy: 0.8266\n",
      "Epoch 95/150\n",
      "283/283 [==============================] - 0s 482us/step - loss: 0.4268 - accuracy: 0.8231\n",
      "Epoch 96/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4250 - accuracy: 0.8215\n",
      "Epoch 97/150\n",
      "283/283 [==============================] - 0s 458us/step - loss: 0.4258 - accuracy: 0.8248\n",
      "Epoch 98/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4259 - accuracy: 0.8242\n",
      "Epoch 99/150\n",
      "283/283 [==============================] - 0s 489us/step - loss: 0.4247 - accuracy: 0.8248\n",
      "Epoch 100/150\n",
      "283/283 [==============================] - 0s 504us/step - loss: 0.4237 - accuracy: 0.8223\n",
      "Epoch 101/150\n",
      "283/283 [==============================] - 0s 486us/step - loss: 0.4238 - accuracy: 0.8222\n",
      "Epoch 102/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4235 - accuracy: 0.8242\n",
      "Epoch 103/150\n",
      "283/283 [==============================] - 0s 472us/step - loss: 0.4233 - accuracy: 0.8243\n",
      "Epoch 104/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4227 - accuracy: 0.8267\n",
      "Epoch 105/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4223 - accuracy: 0.8260\n",
      "Epoch 106/150\n",
      "283/283 [==============================] - 0s 482us/step - loss: 0.4207 - accuracy: 0.8274\n",
      "Epoch 107/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4214 - accuracy: 0.8279\n",
      "Epoch 108/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4205 - accuracy: 0.8291\n",
      "Epoch 109/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4193 - accuracy: 0.8283\n",
      "Epoch 110/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4186 - accuracy: 0.8260\n",
      "Epoch 111/150\n",
      "283/283 [==============================] - 0s 458us/step - loss: 0.4195 - accuracy: 0.8248\n",
      "Epoch 112/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4190 - accuracy: 0.8291\n",
      "Epoch 113/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4179 - accuracy: 0.8284\n",
      "Epoch 114/150\n",
      "283/283 [==============================] - 0s 475us/step - loss: 0.4171 - accuracy: 0.8264\n",
      "Epoch 115/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4177 - accuracy: 0.8281\n",
      "Epoch 116/150\n",
      "283/283 [==============================] - 0s 479us/step - loss: 0.4170 - accuracy: 0.8291\n",
      "Epoch 117/150\n",
      "283/283 [==============================] - 0s 472us/step - loss: 0.4162 - accuracy: 0.8301\n",
      "Epoch 118/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4152 - accuracy: 0.8328\n",
      "Epoch 119/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4168 - accuracy: 0.8279\n",
      "Epoch 120/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4155 - accuracy: 0.8318\n",
      "Epoch 121/150\n",
      "283/283 [==============================] - 0s 482us/step - loss: 0.4161 - accuracy: 0.8286\n",
      "Epoch 122/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4144 - accuracy: 0.8291\n",
      "Epoch 123/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4143 - accuracy: 0.8310\n",
      "Epoch 124/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4146 - accuracy: 0.8314\n",
      "Epoch 125/150\n",
      "283/283 [==============================] - 0s 475us/step - loss: 0.4132 - accuracy: 0.8304\n",
      "Epoch 126/150\n",
      "283/283 [==============================] - 0s 479us/step - loss: 0.4137 - accuracy: 0.8328\n",
      "Epoch 127/150\n",
      "283/283 [==============================] - 0s 479us/step - loss: 0.4138 - accuracy: 0.8283\n",
      "Epoch 128/150\n",
      "283/283 [==============================] - 0s 472us/step - loss: 0.4130 - accuracy: 0.8284\n",
      "Epoch 129/150\n",
      "283/283 [==============================] - 0s 482us/step - loss: 0.4131 - accuracy: 0.8321\n",
      "Epoch 130/150\n",
      "283/283 [==============================] - 0s 475us/step - loss: 0.4134 - accuracy: 0.8335\n",
      "Epoch 131/150\n",
      "283/283 [==============================] - 0s 472us/step - loss: 0.4129 - accuracy: 0.8328\n",
      "Epoch 132/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4128 - accuracy: 0.8325\n",
      "Epoch 133/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4129 - accuracy: 0.8330\n",
      "Epoch 134/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4117 - accuracy: 0.8322\n",
      "Epoch 135/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4122 - accuracy: 0.8331\n",
      "Epoch 136/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4119 - accuracy: 0.8324\n",
      "Epoch 137/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4115 - accuracy: 0.8332\n",
      "Epoch 138/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4105 - accuracy: 0.8330\n",
      "Epoch 139/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4109 - accuracy: 0.8325\n",
      "Epoch 140/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4106 - accuracy: 0.8347\n",
      "Epoch 141/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4101 - accuracy: 0.8339\n",
      "Epoch 142/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4101 - accuracy: 0.8375\n",
      "Epoch 143/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4094 - accuracy: 0.8366\n",
      "Epoch 144/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4106 - accuracy: 0.8318\n",
      "Epoch 145/150\n",
      "283/283 [==============================] - 0s 472us/step - loss: 0.4098 - accuracy: 0.8351\n",
      "Epoch 146/150\n",
      "283/283 [==============================] - 0s 458us/step - loss: 0.4091 - accuracy: 0.8366\n",
      "Epoch 147/150\n",
      "283/283 [==============================] - 0s 461us/step - loss: 0.4090 - accuracy: 0.8354\n",
      "Epoch 148/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4091 - accuracy: 0.8372\n",
      "Epoch 149/150\n",
      "283/283 [==============================] - 0s 465us/step - loss: 0.4085 - accuracy: 0.8376\n",
      "Epoch 150/150\n",
      "283/283 [==============================] - 0s 468us/step - loss: 0.4078 - accuracy: 0.8358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x260239837f0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 150\n",
    "model.fit(X_ros, y_ros, batch_size= 25, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39ac461e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 419us/step - loss: 0.8292 - accuracy: 0.6458\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a09d724d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.645793\n",
      "Precision: 0.103093\n",
      "Recall: 0.740741\n",
      "F1 score: 0.180995\n",
      "ROC score: 0.690618\n",
      "----------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.64      0.77       968\n",
      "           1       0.10      0.74      0.18        54\n",
      "\n",
      "    accuracy                           0.65      1022\n",
      "   macro avg       0.54      0.69      0.48      1022\n",
      "weighted avg       0.93      0.65      0.74      1022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred=(model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print('F1 score: %f' % f1)\n",
    "roc = roc_auc_score(y_test, y_pred)\n",
    "print('ROC score: %f' % roc)\n",
    "print('----------------------------')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c4d55e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
